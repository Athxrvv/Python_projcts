# ğŸ›¡ï¸ Bulletproof Web Scraper (Python)

A **self-validating web scraper** that not only scrapes data from a website but also **tests itself** to detect data quality issues and website structure changes automatically.

This project demonstrates **industry-style web scraping with automated testing**, data cleaning, and error detection.

---

## ğŸš€ Project Idea

Companies use web scrapers to:
- Track competitor prices
- Monitor product listings
- Collect market data

The problem:
> When a website layout or data format changes, scrapers often break silently and store wrong data.

### âœ… Solution
This project builds a **â€œBulletproof Scraperâ€** that:
- Scrapes product data
- Runs automated tests on scraped data
- Fails loudly if something breaks

---

## ğŸŒ Website Used

- **Books to Scrape** (demo e-commerce site)
- Safe and legal for scraping practice  
- URL: http://books.toscrape.com/

---

## ğŸ§° Tech Stack

- **Python 3**
- **Requests** â€“ HTTP requests
- **BeautifulSoup** â€“ HTML parsing
- **Pytest** â€“ automated testing
- **CSV** â€“ data storage
- **Virtual Environment (venv)** â€“ dependency isolation

---

## ğŸ“ Project Structure

```
bulletproof_scraper/
â”œâ”€â”€ scraper.py           # Main scraper script
â”œâ”€â”€ test_scraper.py      # Automated tests
â”œâ”€â”€ utils.py             # Helper functions
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ books.csv           # Output file (generated)
```

---

## ğŸš€ Quick Start

### 1. Create a Virtual Environment
```bash
python -m venv .venv
```

### 2. Activate Virtual Environment
- On Linux/Mac:
  ```bash
  source .venv/bin/activate
  ```
- On Windows:
  ```bash
  .venv\Scripts\activate
  ```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Run the Scraper
```bash
python scraper.py
```

This will:
- Scrape product data from http://books.toscrape.com/
- Save results to `books.csv`
- Display progress in the terminal

**Note:** Internet connection required!

### 5. Run Tests
```bash
pytest test_scraper.py -v
```

This will:
- Test data quality
- Verify scraping functionality
- Catch potential issues early

---

## ğŸ“ Output

The scraper creates `books.csv` with columns:
- **title** - Book title
- **price** - Price in pounds (Â£)
- **image_url** - Product image URL

---

## ğŸ¯ Key Features

- âœ… **Robust Error Handling** - Handles network failures gracefully
- âœ… **Automated Testing** - Pytest tests ensure data quality
- âœ… **Data Validation** - Tests check for expected data format
- âœ… **CSV Export** - Clean, structured data output
- âœ… **Configurable** - Easy to modify pages to scrape

---

## ğŸ§ª What the Tests Check

1. Data structure is correct
2. All required fields are present
3. Price format is valid
4. No empty or null values
5. Reasonable number of results

---

## ğŸ”§ Troubleshooting

### Issue: Network errors
**Solution:** Check your internet connection and ensure http://books.toscrape.com/ is accessible

### Issue: Tests fail
**Solution:** This usually means the website structure changed. Review the scraper logic and update selectors.

### Issue: Empty CSV file
**Solution:** Website may be down or blocking requests. Try again later.

---

## ğŸ“š Learning Notes

This project demonstrates:
- Web scraping with `requests` and `BeautifulSoup`
- Test-driven development with `pytest`
- CSV data export
- Error handling best practices
- Virtual environment management
